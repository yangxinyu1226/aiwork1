import streamlit as st
import openai
import os
import json
import glob
import time # ç”¨äºæ¨¡æ‹Ÿæ“ä½œè€—æ—¶æˆ–æ·»åŠ å°‘é‡å»¶è¿Ÿï¼Œæœ‰æ—¶æœ‰åŠ©äºUIæ›´æ–°

# --- DeepSeek API é…ç½® ---
# å»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½® API Key
openai.api_key = os.getenv("DEEPSEEK_API_KEY")
# æŒ‰ç…§ä½ çš„åé¦ˆï¼Œæš‚æ—¶ä¿ç•™æ­¤åœ°å€ï¼Œå› ä¸ºä½ æåˆ° /v1 ä¼šè¿”å› 404
openai.base_url = "https://api.deepseek.com"
openai.timeout = 60.0 # å¢åŠ APIè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé˜²æ­¢ç½‘ç»œä¸ç¨³å®šå¯¼è‡´è¯·æ±‚å¤±è´¥

# æ£€æŸ¥ API Key æ˜¯å¦å·²è®¾ç½®ï¼Œå¦‚æœæœªè®¾ç½®åˆ™åœæ­¢åº”ç”¨å¹¶æ˜¾ç¤ºé”™è¯¯
if openai.api_key is None:
    st.error("é”™è¯¯ï¼šDEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚")
    st.markdown("è¯·åœ¨è¿è¡Œ Streamlit åº”ç”¨å‰è®¾ç½®æ­¤ç¯å¢ƒå˜é‡ã€‚ä¾‹å¦‚ï¼š")
    st.code("export DEEPSEEK_API_KEY=\"sk-YOUR_API_KEY_HERE\" # Linux/macOS")
    st.code("set DEEPSEEK_API_KEY=\"sk-YOUR_API_KEY_HERE\" # Windows CMD")
    st.code("$env:DEEPSEEK_API_KEY=\"sk-YOUR_API_KEY_HERE\" # Windows PowerShell")
    st.stop() # åœæ­¢ Streamlit åº”ç”¨çš„è¿è¡Œ

# --- å®šä¹‰é€šç”¨çš„å›¾ç‰‡æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ ---
IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp']

# --- æœ¬åœ°å·¥å…·å‡½æ•°å®ç° ---
# è¿™äº›å‡½æ•°æ˜¯ AI é€šè¿‡ MCP è°ƒç”¨çš„â€œèº«ä½“â€
def read_local_file(file_path):
    """
    è¯»å–ç”¨æˆ·æœ¬åœ°æŒ‡å®šè·¯å¾„çš„æ–‡æœ¬æ–‡ä»¶å†…å®¹ã€‚
    """
    if not os.path.exists(file_path):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}"}
    if not os.path.isfile(file_path):
        return {"error": f"è¿™ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼š{file_path}"}

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"success": True, "content": content}
    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{str(e)}"}

def create_text_file(file_path, content):
    """
    åœ¨æœ¬åœ°åˆ›å»ºæˆ–è¦†ç›–æ–‡æœ¬æ–‡ä»¶ã€‚
    """
    try:
        # è·å–æ–‡ä»¶è·¯å¾„ä¸­çš„ç›®å½•éƒ¨åˆ†
        directory = os.path.dirname(file_path)
        # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒ
        if directory and not os.path.exists(directory):
            os.makedirs(directory, exist_ok=True) # exist_ok=True é¿å…ç›®å½•å·²å­˜åœ¨æ—¶æŠ¥é”™

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return {"success": True, "message": f"æ–‡ä»¶ '{file_path}' å·²æˆåŠŸåˆ›å»º/æ›´æ–°ã€‚"}
    except Exception as e:
        return {"error": f"åˆ›å»º/å†™å…¥æ–‡ä»¶å¤±è´¥ï¼š{str(e)}"}

def batch_rename_images(folder_path, naming_rule, base_name=None, start_number=1):
    """
    æ ¹æ®æŒ‡å®šè§„åˆ™æ‰¹é‡é‡å‘½åæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡æ–‡ä»¶ã€‚
    ç›®å‰ä»…æ”¯æŒ 'sequential'ï¼ˆæŒ‰é¡ºåºç¼–å·ï¼‰è§„åˆ™ã€‚
    """
    if not os.path.isdir(folder_path):
        return {"error": f"æŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•ï¼š{folder_path}"}

    image_files = []
    for ext in IMAGE_EXTENSIONS:
        # ä½¿ç”¨ glob æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…æ‰©å±•åçš„æ–‡ä»¶ï¼Œå¹¶ç¡®ä¿æ˜¯æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
        found_files = glob.glob(os.path.join(folder_path, f'*{ext}'))
        image_files.extend([f for f in found_files if os.path.isfile(f)])
    
    image_files.sort() # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿é¡ºåºç¼–å·çš„é€»è¾‘ä¸€è‡´æ€§

    if not image_files:
        return {"message": f"åœ¨æ–‡ä»¶å¤¹ '{folder_path}' ä¸­æœªæ‰¾åˆ°ä»»ä½•æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶ã€‚"}

    results = []
    try:
        if naming_rule == "sequential":
            if not base_name:
                return {"error": "å½“è§„åˆ™ä¸º 'sequential' æ—¶ï¼Œ'base_name' å‚æ•°ä¸èƒ½ä¸ºç©ºã€‚"}
            
            # ç¡®å®šæ–°æ–‡ä»¶åçš„æ•°å­—ä½æ•°ï¼Œä¾‹å¦‚å¦‚æœæ€»å…±æœ‰123å¼ å›¾ï¼Œstart_numberæ˜¯1ï¼Œåˆ™æœ€å¤§ç¼–å·æ˜¯123ï¼Œéœ€è¦3ä½ï¼ˆ001, 002...ï¼‰
            num_digits = len(str(len(image_files) + start_number - 1)) 

            for i, old_path in enumerate(image_files):
                _ , ext = os.path.splitext(os.path.basename(old_path)) # åªä¿ç•™æ‰©å±•å
                
                new_name = f"{base_name}-{str(start_number + i).zfill(num_digits)}{ext}"
                new_path = os.path.join(folder_path, new_name)
                
                # æ£€æŸ¥æ–°è·¯å¾„æ˜¯å¦ä¸æ—§è·¯å¾„ç›¸åŒï¼ˆé¿å…ä¸å¿…è¦çš„é‡å‘½åæ“ä½œï¼Œä¾‹å¦‚é‡å¤è¿è¡Œï¼‰
                if os.path.exists(new_path) and os.path.samefile(old_path, new_path):
                    results.append({"original": os.path.basename(old_path), "new": "æœªæ”¹å˜ (æ–°æ—§æ–‡ä»¶åç›¸åŒ)"})
                else:
                    os.rename(old_path, new_path)
                    results.append({"original": os.path.basename(old_path), "new": new_name})

            return {"success": True, "message": f"æˆåŠŸæŒ‰é¡ºåºé‡å‘½å {len(results)} å¼ å›¾ç‰‡ã€‚", "details": results}

        else:
            return {"error": f"ä¸æ”¯æŒçš„é‡å‘½åè§„åˆ™ï¼š{naming_rule}ã€‚å½“å‰ä»…æ”¯æŒ 'sequential' é¡ºåºç¼–å·é‡å‘½åã€‚"}

    except Exception as e:
        # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # import traceback
        # traceback.print_exc()
        return {"error": f"é‡å‘½åè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"}

# --- æ˜ å°„å·¥å…·ååˆ°å®é™…çš„å‡½æ•° ---
# ç¡®ä¿æ‰€æœ‰å‡½æ•°åœ¨æ­¤å­—å…¸å®šä¹‰ä¹‹å‰è¢«å®šä¹‰
available_functions = {
    "read_local_file": read_local_file,
    "create_text_file": create_text_file,
    "batch_rename_images": batch_rename_images
}

# --- DeepSeek AI å¯ç”¨çš„å·¥å…·å®šä¹‰ï¼ˆMCP åè®®ï¼‰---
# å°†æ‰€æœ‰å·¥å…·çš„æè¿°éƒ½åŒ…å«åœ¨æ­¤åˆ—è¡¨ä¸­ï¼Œç”¨äºå‘Šè¯‰ AI å®ƒèƒ½åšä»€ä¹ˆ
tools = [
    {
        "type": "function",
        "function": {
            "name": "read_local_file",
            "description": "è¯»å–ç”¨æˆ·æœ¬åœ°æŒ‡å®šè·¯å¾„çš„æ–‡æœ¬æ–‡ä»¶å†…å®¹ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "è¦è¯»å–çš„æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ '/Users/User/Documents/my_doc.txt' æˆ– 'C:\\data\\log.txt'"
                    }
                },
                "required": ["file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "create_text_file",
            "description": "åœ¨ç”¨æˆ·æœ¬åœ°åˆ›å»ºæˆ–è¦†ç›–æ–‡æœ¬æ–‡ä»¶ã€‚å¦‚æœçˆ¶ç›®å½•ä¸å­˜åœ¨ï¼Œå°†å°è¯•åˆ›å»ºã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "è¦åˆ›å»ºæˆ–è¦†ç›–çš„æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ '/Users/User/Documents/new_report.txt' æˆ– 'C:\\data\\temp\\report.txt'"
                    },
                    "content": {
                        "type": "string",
                        "description": "è¦å†™å…¥æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹ã€‚"
                    }
                },
                "required": ["file_path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "batch_rename_images",
            "description": "æ ¹æ®æŒ‡å®šè§„åˆ™æ‰¹é‡é‡å‘½åæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡æ–‡ä»¶ã€‚ç›®å‰åªæ”¯æŒæŒ‰é¡ºåºç¼–å·é‡å‘½åã€‚è¯·åŠ¡å¿…æä¾›åŒ…å«å›¾ç‰‡çš„å®Œæ•´æ–‡ä»¶å¤¹çš„**ç»å¯¹è·¯å¾„**ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "folder_path": {
                        "type": "string",
                        "description": "åŒ…å«è¦é‡å‘½åçš„å›¾ç‰‡çš„æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ 'C:\\Users\\YourName\\Pictures\\æ—…è¡Œç…§ç‰‡' æˆ– '/Users/YourName/Desktop/æˆ‘çš„å›¾ç‰‡'"
                    },
                    "naming_rule": {
                        "type": "string",
                        "description": "é‡å‘½åè§„åˆ™ã€‚'sequential' è¡¨ç¤ºæŒ‰é¡ºåºç¼–å·ã€‚",
                        "enum": ["sequential"] # æ˜ç¡®åªæ”¯æŒ sequential
                    },
                    "base_name": {
                        "type": "string",
                        "description": "å½“ naming_rule ä¸º 'sequential' æ—¶ï¼ŒæŒ‡å®šæ–°æ–‡ä»¶åçš„åŸºç¡€éƒ¨åˆ†ï¼Œä¾‹å¦‚ 'ç…§ç‰‡'ã€‚",
                        "nullable": True
                    },
                    "start_number": {
                        "type": "integer",
                        "description": "å½“ naming_rule ä¸º 'sequential' æ—¶ï¼ŒæŒ‡å®šèµ·å§‹ç¼–å·ï¼ˆä¾‹å¦‚ 1ï¼‰ã€‚",
                        "default": 1,
                        "nullable": True
                    }
                },
                "required": ["folder_path", "naming_rule", "base_name"] # ç¡®ä¿ base_name ä¹Ÿæ˜¯å¿…å¡«é¡¹
            }
        }
    }
]

# --- Streamlit ç•Œé¢æ„å»º ---
st.set_page_config(page_title="AI æ–‡ä»¶ä¸ç…§ç‰‡åŠ©æ‰‹", layout="centered")
st.title("ğŸ—‚ï¸ AI æ–‡ä»¶ä¸ç…§ç‰‡åŠ©æ‰‹")

st.markdown("""
è¿™ä¸ªæ™ºèƒ½åŠ©æ‰‹å¯ä»¥å¸®ä½ å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
* **è¯»å–æœ¬åœ°æ–‡æœ¬æ–‡ä»¶å†…å®¹**
* **åˆ›å»ºæˆ–ä¿®æ”¹æœ¬åœ°æ–‡æœ¬æ–‡ä»¶**
* **æ‰¹é‡æŒ‰é¡ºåºé‡å‘½åæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡** (ä¾‹å¦‚ï¼š`æˆ‘çš„ç…§ç‰‡-001.jpg`, `æˆ‘çš„ç…§ç‰‡-002.jpg`)

è¯·åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„æŒ‡ä»¤ã€‚
""")

# åˆå§‹åŒ– Streamlit session_state ä¸­çš„æ¶ˆæ¯å†å²å’ŒèŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡ä»¶ä¸ç…§ç‰‡åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘è¯»å–ã€åˆ›å»ºæ–‡æœ¬æ–‡ä»¶ï¼Œä»¥åŠæ‰¹é‡é‡å‘½åå›¾ç‰‡ã€‚å½“ä½ éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨æä¾›çš„å·¥å…·ï¼Œå¹¶ç¡®ä¿æä¾›å®Œæ•´ä¸”æ­£ç¡®çš„è·¯å¾„å’Œå¿…è¦å‚æ•°ã€‚"}
    ]
    st.session_state.chat_history = [] # ç”¨äºåœ¨UIä¸Šæ˜¾ç¤ºç»™ç”¨æˆ·çš„å¯¹è¯å†å²

# æ˜¾ç¤ºä¹‹å‰çš„å¯¹è¯å†å²
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è·å–ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¾“å…¥ä½ çš„æŒ‡ä»¤...")

# åœ¨æŸä¸ªåˆé€‚çš„ä½ç½®ï¼Œæ¯”å¦‚ st.chat_input ä¹‹å‰æˆ–ä¹‹å
if st.button("å¼€å§‹æ–°å¯¹è¯"):
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡ä»¶ä¸ç…§ç‰‡åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘è¯»å–ã€åˆ›å»ºæ–‡æœ¬æ–‡ä»¶ï¼Œä»¥åŠæ‰¹é‡é‡å‘½åå›¾ç‰‡ã€‚å½“ä½ éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨æä¾›çš„å·¥å…·ï¼Œå¹¶ç¡®ä¿æä¾›å®Œæ•´ä¸”æ­£ç¡®çš„è·¯å¾„å’Œå¿…è¦å‚æ•°ã€‚"}
    ]
    st.session_state.chat_history = []
    st.experimental_rerun() # é‡æ–°è¿è¡Œåº”ç”¨ä»¥æ›´æ–°UI

if user_input:
    # 1. å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ° Streamlit çš„èŠå¤©å†å²å’Œ DeepSeek çš„æ¶ˆæ¯å†å²ä¸­
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("AI æ­£åœ¨æ€è€ƒ..."): # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
        # æ ¸å¿ƒé€»è¾‘åŒ…è£¹åœ¨ä¸€ä¸ªå¤§çš„ try å—ä¸­ï¼Œæ•è·æ‰€æœ‰APIå’Œè¿è¡Œæ—¶é”™è¯¯
        try: 
            with st.status("æ­£åœ¨ä¸ DeepSeek AI äº¤äº’...", expanded=True) as status_message:
                # Debugging 1: Show messages before first API call
                status_message.write("--- DeepSeek API è°ƒç”¨å‰ï¼ˆæ¶ˆæ¯å†å²ï¼‰ ---")
                for msg in st.session_state.messages:
                    status_message.write(msg)
                status_message.write("------------------------------------")
                print("\n--- CONSOLE LOG: MESSAGES BEFORE FIRST API CALL ---")
                
                status_message.write("å‘èµ·ç¬¬ä¸€æ¬¡ DeepSeek API è¯·æ±‚...")
                for msg in st.session_state.messages:
                    print(msg)
                print("--------------------------------------------------\n")
                # 2. ç¬¬ä¸€æ¬¡è°ƒç”¨ DeepSeek AIï¼Œè®©å…¶å†³å®šæ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
                response = openai.chat.completions.create(
                    model="deepseek-chat",
                    messages=st.session_state.messages,
                    tools=tools, # ä¼ é€’æ‰€æœ‰å®šä¹‰çš„å·¥å…·åˆ—è¡¨
                    tool_choice="auto" # å…è®¸æ¨¡å‹è‡ªåŠ¨é€‰æ‹©æ˜¯å¦ä½¿ç”¨å·¥å…·
                )
                status_message.write("ç¬¬ä¸€æ¬¡ DeepSeek API è¯·æ±‚å®Œæˆã€‚")

                response_message = response.choices[0].message
                tool_calls = response_message.tool_calls

                # 3. å¤„ç† AI çš„ç›´æ¥å›å¤ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                # å¦‚æœ AI æœ‰æ–‡æœ¬å†…å®¹å›å¤ï¼Œå…ˆæ˜¾ç¤ºå®ƒï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° DeepSeek çš„æ¶ˆæ¯å†å²
                if response_message.content:
                    st.session_state.chat_history.append({"role": "assistant", "content": response_message.content})
                    # å°†æ­¤æ¶ˆæ¯æ·»åŠ åˆ° DeepSeek çš„å†…éƒ¨å†å²ï¼Œä»¥ä¾¿å®ƒèƒ½è®°ä½
                    st.session_state.messages.append(response_message)
                    with st.chat_message("assistant"):
                        st.markdown(response_message.content)
                    status_message.update(label="DeepSeek AI å·²å›å¤", state="complete", expanded=False)
                    st.rerun() # ç«‹å³åˆ·æ–°UIæ˜¾ç¤ºAIçš„ç›´æ¥å›å¤


                # 4. å¦‚æœ DeepSeek å†³å®šè°ƒç”¨å·¥å…·
                if tool_calls:
                    # å…³é”®æ­¥éª¤ï¼šç¡®ä¿åŒ…å« tool_calls çš„ response_message è¢«æ·»åŠ åˆ° DeepSeek çš„æ¶ˆæ¯å†å²ä¸­
                    # åªæœ‰å½“æ­¤ response_message æ˜¯çº¯ç²¹çš„å·¥å…·è°ƒç”¨ï¼ˆå³æ²¡æœ‰ contentï¼‰æ—¶ï¼Œæ‰åœ¨è¿™é‡Œæ·»åŠ ã€‚
                    # å¦‚æœå®ƒæœ‰ contentï¼Œé‚£ä¹ˆå·²ç»åœ¨ä¸Šé¢çš„ if block ä¸­è¢«æ·»åŠ äº†ã€‚
                    if not response_message.content:
                        st.session_state.messages.append(response_message) # è®°å½• AI å†³å®šè°ƒç”¨å·¥å…·è¿™ä¸€äº‹å®

                    # Debugging 2: Show messages after AI's tool_calls message is appended
                    status_message.write("--- AI å†³å®šè°ƒç”¨å·¥å…·åï¼ˆæ¶ˆæ¯å†å²ï¼‰ ---")
                    for msg in st.session_state.messages:
                        status_message.write(msg)
                    status_message.write("------------------------------------")
                    print("\n--- CONSOLE LOG: MESSAGES AFTER AI'S TOOL_CALLS MESSAGE ---")
                    for msg in st.session_state.messages:
                        print(msg)
                    print("----------------------------------------------------------\n")
                    
                    status_message.write("AI å†³å®šè°ƒç”¨å·¥å…·ï¼Œå‡†å¤‡æ‰§è¡Œ...")
                    # æ˜¾ç¤º AI æ­£åœ¨å‡†å¤‡è°ƒç”¨å·¥å…·çš„æç¤º
                    tool_request_msg = "AI æ­£åœ¨å‡†å¤‡è°ƒç”¨å·¥å…·..."
                    st.session_state.chat_history.append({"role": "assistant", "content": tool_request_msg})
                    with st.chat_message("assistant"):
                        st.markdown(tool_request_msg)
                    #st.rerun() # ç«‹å³åˆ·æ–°UIæ˜¾ç¤ºAIçš„æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚â€œAI æ­£åœ¨å‡†å¤‡è°ƒç”¨å·¥å…·...â€ï¼‰

                    # 5. éå†å¹¶æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                    for tool_call in tool_calls:
                        function_name = tool_call.function.name
                        function_to_call = available_functions.get(function_name)

                        if function_to_call:
                            # è§£æå·¥å…·è°ƒç”¨çš„å‚æ•°
                            function_args = json.loads(tool_call.function.arguments)
                            
                            # ä½¿ç”¨ st.status æ¥æ˜¾ç¤ºå·¥å…·æ‰§è¡Œè¿›åº¦
                            with st.status(f"æ­£åœ¨æ‰§è¡Œå·¥å…·ï¼š`{function_name}`", expanded=True) as tool_exec_status:
                                tool_exec_status.write(f"å‚æ•°ï¼š`{function_args}`")
                                
                                # æ˜¾ç¤ºæ­£åœ¨æ‰§è¡Œå·¥å…·çš„ä¿¡æ¯
                                tool_log_msg = f"AI æ­£åœ¨æ‰§è¡Œå·¥å…·ï¼š`{function_name}`ï¼Œå‚æ•°ï¼š`{function_args}`"
                                st.session_state.chat_history.append({"role": "assistant", "content": tool_log_msg})
                                # æ³¨æ„ï¼šè¿™é‡Œä¸ st.rerun()ï¼Œè®© st.status æ¥æ§åˆ¶ UI åˆ·æ–°
                                
                                # æ‰§è¡Œæœ¬åœ°å·¥å…·å‡½æ•°
                                tool_output = function_to_call(**function_args)
                                
                                # æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœ
                                tool_output_msg = f"å·¥å…· `{function_name}` æ‰§è¡Œå®Œæ¯•ï¼Œç»“æœï¼š\n```json\n{json.dumps(tool_output, indent=2, ensure_ascii=False)}\n```"
                                st.session_state.chat_history.append({"role": "assistant", "content": tool_output_msg})
                                # æ³¨æ„ï¼šè¿™é‡Œä¸ st.rerun()
                                
                                with st.chat_message("assistant"):
                                    st.markdown(tool_output_msg)

                                # æ›´æ–° st.status çš„çŠ¶æ€
                                tool_exec_status.update(label=f"å·¥å…· `{function_name}` æ‰§è¡ŒæˆåŠŸ", state="complete", expanded=False)

                            # 6. å°†å·¥å…·çš„è¾“å‡ºä½œä¸º `role="tool"` æ¶ˆæ¯æ·»åŠ åˆ° DeepSeek çš„æ¶ˆæ¯å†å²ä¸­
                            st.session_state.messages.append(
                                {
                                    "tool_call_id": tool_call.id, # å¿…é¡»ä¸åŸå§‹ tool_call çš„ ID åŒ¹é…
                                    "role": "tool",
                                    "name": function_name,
                                    "content": json.dumps(tool_output, ensure_ascii=False), # å·¥å…·è¾“å‡ºå¿…é¡»æ˜¯ JSON å­—ç¬¦ä¸²
                                }
                            )
                        else:
                            # å¤„ç†æœªçŸ¥å·¥å…·çš„æƒ…å†µ
                            error_msg = f"AI é”™è¯¯ï¼šæœªçŸ¥çš„å·¥å…· '{function_name}'ã€‚"
                            st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
                            st.session_state.messages.append({"role": "tool", "name": function_name, "content": error_msg})
                            with st.chat_message("assistant"):
                                st.error(error_msg)
                            st.rerun() # ç«‹å³åˆ·æ–°ï¼Œæ˜¾ç¤ºæœªçŸ¥å·¥å…·é”™è¯¯

                    # Debugging 3: Show messages after tool's response message is appended
                    status_message.write("--- å·¥å…·ç»“æœæ·»åŠ åï¼ˆæ¶ˆæ¯å†å²ï¼‰ ---")
                    for msg in st.session_state.messages:
                        status_message.write(msg)
                    status_message.write("------------------------------------")
                    print("\n--- CONSOLE LOG: MESSAGES BEFORE SECOND API CALL (After Tool Output) ---")
                    for msg in st.session_state.messages:
                        print(msg)
                    print("----------------------------------------------------------------------\n")

                    status_message.write("æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œæ­£åœ¨å‘ DeepSeek å›ä¼ ç»“æœå¹¶è·å–æœ€ç»ˆå›å¤...")
                    # 7. ç¬¬äºŒæ¬¡è°ƒç”¨ DeepSeek AIï¼Œè®©å…¶åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
                    final_response = openai.chat.completions.create(
                        model="deepseek-chat",
                        messages=st.session_state.messages # æ­¤æ—¶çš„ messages åˆ—è¡¨åŒ…å«äº†å®Œæ•´çš„å·¥å…·è°ƒç”¨å’Œç»“æœå†å²
                    )
                    status_message.write("æœ€ç»ˆå›å¤è·å–æˆåŠŸã€‚")
                    final_ai_message = final_response.choices[0].message
                    
                    # å°†æœ€ç»ˆå›å¤æ·»åŠ åˆ°æ˜¾ç¤ºå†å²å’Œ DeepSeek çš„æ¶ˆæ¯å†å²
                    st.session_state.chat_history.append({"role": "assistant", "content": final_ai_message.content})
                    st.session_state.messages.append(final_ai_message)
                    with st.chat_message("assistant"):
                        st.markdown(final_ai_message.content)
                    
                    status_message.update(label="DeepSeek AI æ€è€ƒå®Œæˆï¼", state="complete", expanded=False)
                    st.rerun() 

                # å¦‚æœ DeepSeek ç›´æ¥ç»™å‡ºå›å¤ï¼Œæ²¡æœ‰è°ƒç”¨å·¥å…·
                elif not tool_calls and not response_message.content:
                    # è¿™ç§æƒ…å†µé€šå¸¸ä¸ä¼šå‘ç”Ÿï¼Œå› ä¸ºè‡³å°‘ä¼šæœ‰ä¸€ä¸ª content æˆ– tool_calls
                    # ä½†ä½œä¸ºé˜²å¾¡æ€§ç¼–ç¨‹ï¼Œä»¥é˜²ä¸‡ä¸€
                    st.session_state.chat_history.append({"role": "assistant", "content": "AI æ²¡æœ‰ç»™å‡ºæ˜ç¡®å›å¤ï¼Œä¹Ÿæ²¡æœ‰è°ƒç”¨å·¥å…·ã€‚"})
                    st.session_state.messages.append({"role": "assistant", "content": "AI æ²¡æœ‰ç»™å‡ºæ˜ç¡®å›å¤ï¼Œä¹Ÿæ²¡æœ‰è°ƒç”¨å·¥å…·ã€‚"})
                    with st.chat_message("assistant"):
                        st.markdown("AI æ²¡æœ‰ç»™å‡ºæ˜ç¡®å›å¤ï¼Œä¹Ÿæ²¡æœ‰è°ƒç”¨å·¥å…·ã€‚")
                    status_message.update(label="DeepSeek AI æ€è€ƒå®Œæˆï¼", state="complete", expanded=False)
                    st.rerun()

        # æ‰€æœ‰çš„ API ç›¸å…³å¼‚å¸¸æ•è·éƒ½æ”¾åœ¨è¿™ä¸ªä¸» try å—çš„åé¢
        except openai.APIConnectionError as e:
            error_msg = f"æ— æ³•è¿æ¥åˆ° DeepSeek APIï¼š{e}"
            st.error(error_msg)
            # ç¡®ä¿ status_message å­˜åœ¨ä¸”æœ‰æ•ˆ
            if 'status_message' in locals():
                status_message.update(label="API è¿æ¥é”™è¯¯", state="error", expanded=True)
            st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
            st.rerun()
        except openai.RateLimitError as e:
            error_msg = f"è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ï¼š{e}"
            st.error(error_msg)
            if 'status_message' in locals():
                status_message.update(label="é€Ÿç‡é™åˆ¶é”™è¯¯", state="error", expanded=True)
            st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
            st.rerun()
        except openai.APIStatusError as e:
            error_msg = f"DeepSeek API è¿”å›é”™è¯¯çŠ¶æ€ {e.status_code}: {e.response.text}"
            st.error(error_msg)
            if 'status_message' in locals():
                status_message.update(label="API çŠ¶æ€é”™è¯¯", state="error", expanded=True)
            st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
            st.rerun()
        except Exception as e: # æ•è·æ‰€æœ‰å…¶ä»–æœªçŸ¥é”™è¯¯
            error_msg = f"å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e}"
            st.error(error_msg)
            if 'status_message' in locals():
                status_message.update(label="æœªçŸ¥é”™è¯¯", state="error", expanded=True)
            st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
            st.rerun()
